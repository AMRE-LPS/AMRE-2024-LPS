import subprocess
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.ticker import ScalarFormatter
import numpy as np
import pwlf
import sys
import toml
import datetime
 
 
#Parameters for running benchmark, saved in config.toml
 
config = toml.load('config.toml')

# Extract the information
max_time = config['max_time']
thread_counts = config['thread_counts']
prime_numbers = config['prime_numbers']
 
#initializing lists to store data
data_primes = []
data_threads = []
data_num_events = []
datetime_stamp = datetime.datetime.now().strftime("%Y-%m-%d %Hh%Mm%Ss")
 
#data is a panda DataFrame object, preferably with 3 columns num_prime, num_virtual cores, num_events
def piecewise_regression(data):
    x = data["num_threads"].values
    y = data["num_events"].values
 
    #Create a piecewise linear fit object
    breakpoint = None
    best_metric = float('-inf')
 
    #loop through thread_counts list
    for threads in thread_counts:
        #feed data through model
        model = pwlf.PiecewiseLinFit(x, y)
        #using threads as breakpoints in 2-segment regression
        model.fit_with_breaks([0, threads, thread_counts[len(thread_counts) - 1] + 1])
        #calculate r^2
        metric = model.r_squared()
 
        #save the model with highest r^2
        if metric > best_metric:
            best_metric = metric
            breakpoint = threads
 
    return breakpoint
 
#take full dataset generated by sysbench, preferably preferably with 3 columns num_prime, num_virtual cores, num_events
def determine_optimal_threads(data):
    #store prediction of threads based on different prime number tests using piecewise regression
    frequency_dict = {key: 0 for key in thread_counts}
   
    #split data to corresponding dataframe based on different max_primes
    data_by_max_primes_dict = {max_prime: group for max_prime, group in data.groupby('max_prime')}
 
    for max_prime in data_by_max_primes_dict.values():
        optimal_thread = piecewise_regression(max_prime)
        frequency_dict[optimal_thread] += 1
 
    print("\nThe benchmark indicates that number of virtual cores this computer has is likely to be:", max(frequency_dict, key=frequency_dict.get))
 
def sysbench_cpu(thread_count, prime_num):
    cmd = f"sysbench cpu --max-time={max_time} --num-threads={thread_count} run"
    output = subprocess.check_output(cmd, shell=True).decode()
    for line in output.split('\n'):
        if "total number of events:" in line:
            data_primes.append(prime_num)
            data_threads.append(thread_count)
            data_num_events.append(int(line.split()[-1]))
 
def progress_bar(current_step, total_steps):
    percent_complete = (current_step / total_steps) * 100
    bar_length = 50  # Length of the progress bar
    filled_length = int(bar_length * percent_complete // 100)
    bar = '#' * filled_length + '-' * (bar_length - filled_length)
    
    # Clear the line and print the progress bar
    sys.stdout.write(f'\r{" " * (bar_length + 20)}')
    sys.stdout.write(f'\r|{bar}| {percent_complete:.2f}% Complete')
    sys.stdout.flush()
 
def run_benchmark():
    total_iterations = len(prime_numbers) * len(thread_counts)
    current_iteration = 0
    
    for primes in prime_numbers:
        for threads in thread_counts:
            sysbench_cpu(threads, primes)
            current_iteration += 1
            progress_bar(current_iteration, total_iterations)
 
    data_table = {
            "max_prime": data_primes,
            "num_threads": data_threads,
            "num_events": data_num_events
        }
    return pd.DataFrame(data_table)
 
#creates a csv file of the dataframe
def create_csv_file(df):
    df.to_csv("data_{}.csv".format(datetime_stamp), index=False)
 
#creates a png of the normalized dataframe
def create_graph_file(df):
    groups = df.groupby('max_prime')
    plt.figure(figsize=(10, 6))
 
    for max_prime, group in groups:
        min_events = group['num_events'].min()
        max_events = group['num_events'].max()
        if max_events != min_events:  # Ensure no division by zero
            normalized_events = (group['num_events'] - min_events) / (max_events - min_events)
        else:
            normalized_events = np.zeros_like(group['num_events'])  # All values are the same, normalize to zero
        plt.plot(group['num_threads'], normalized_events, marker='o', linestyle='-', label=f'{max_prime}')
 
    #configure graph
    plt.title(f'Performance of Sysbench CPU Benchmark with Time = {max_time}')
    plt.legend(title='Maximum Prime Numbers')
    plt.xlabel('Number of Threads')
    plt.ylabel('Number of Events')
    plt.grid(True)
 
    #save graph as a png
    plt.savefig('data_plot_{}.png'.format(datetime_stamp))
 
if __name__ == "__main__":
 
    data_frame = run_benchmark()
    create_csv_file(data_frame)
    create_graph_file(data_frame)
    determine_optimal_threads(data_frame)

