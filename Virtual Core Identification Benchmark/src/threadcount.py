import subprocess
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.ticker import ScalarFormatter
import numpy as np
import pwlf
import sys
import toml
import datetime


# Parameters for running benchmark, saved in config.toml

config = toml.load("config.toml")

# Extract the information
max_time = config["max_time"]
thread_counts = config["thread_counts"]
prime_number = config["prime_numbers"]
iteration = config["iteration"]

# initializing lists to store data
data_iteration = []
data_threads = []
data_num_events = []
datetime_stamp = datetime.datetime.now().strftime("%Y-%m-%d %Hh%Mm%Ss")


# data is a panda DataFrame object, preferably with 3 columns num_prime, num_virtual cores, num_events
def piecewise_regression(data):
    x = data["num_threads"].values
    y = data["num_events"].values

    # Create a piecewise linear fit object
    breakpoint = None
    best_metric = float("-inf")

    # loop through thread_counts list
    for threads in thread_counts:
        # feed data through model
        model = pwlf.PiecewiseLinFit(x, y)
        # using threads as breakpoints in 2-segment regression
        model.fit_with_breaks([0, threads, thread_counts[len(thread_counts) - 1] + 1])
        # calculate r^2
        metric = model.r_squared()

        # save the model with highest r^2
        if metric > best_metric:
            best_metric = metric
            breakpoint = threads

    return breakpoint


# take full dataset generated by sysbench, preferably preferably with 3 columns num_prime, num_virtual cores, num_events
def determine_optimal_threads(data):
    # store prediction of threads based on different prime number tests using piecewise regression
    frequency_dict = {key: 0 for key in thread_counts}

    # split data to corresponding dataframe based on different max_primes
    data_by_iterations_dict = {
        iterations: group for iterations, group in data.groupby("num_iterations")
    }

    for data_per_iteration in data_by_iterations_dict.values():
        optimal_thread = piecewise_regression(data_per_iteration)
        frequency_dict[optimal_thread] += 1

    print(
        "\nThe benchmark indicates that number of virtual cores this computer has is likely to be:",
        max(frequency_dict, key=frequency_dict.get),
    )


def sysbench_cpu(thread_count, iteration):
    cmd = f"sysbench cpu --cpu-max-prime={prime_number} --max-time={max_time} --num-threads={thread_count} run"
    output = subprocess.check_output(cmd, shell=True).decode()
    for line in output.split("\n"):
        if "total number of events:" in line:
            data_iteration.append(iteration)
            data_threads.append(thread_count)
            data_num_events.append(int(line.split()[-1]))


def progress_bar(current_step, total_steps):
    percent_complete = (current_step / total_steps) * 100
    bar_length = 50  # Length of the progress bar
    filled_length = int(bar_length * percent_complete // 100)
    bar = "#" * filled_length + "-" * (bar_length - filled_length)

    # Clear the line and print the progress bar
    sys.stdout.write(f'\r{" " * (bar_length + 20)}')
    sys.stdout.write(f"\r|{bar}| {percent_complete:.2f}% Complete")
    sys.stdout.flush()


def run_benchmark():
    total_iterations = iteration * len(thread_counts)
    current_iteration = 0

    for iteration_index in range(1, iteration + 1):
        for threads in thread_counts:
            sysbench_cpu(threads, iteration_index)
            current_iteration += 1
            progress_bar(current_iteration, total_iterations)

    data_table = {
        "num_iterations": data_iteration,
        "num_threads": data_threads,
        "num_events": data_num_events,
    }
    return pd.DataFrame(data_table)


# creates a csv file of the dataframe
def create_csv_file(df):
    df.to_csv("data_{}.csv".format(datetime_stamp), index=False)


# creates a png of the normalized dataframe
def create_graph_file(df):
    groups = df.groupby("num_iterations")
    plt.figure(figsize=(10, 6))

    for max_prime, group in groups:
        min_events = group["num_events"].min()
        max_events = group["num_events"].max()
        if max_events != min_events:  # Ensure no division by zero
            normalized_events = (group["num_events"] - min_events) / (
                max_events - min_events
            )
        else:
            normalized_events = np.zeros_like(
                group["num_events"]
            )  # All values are the same, normalize to zero
        plt.plot(
            group["num_threads"],
            normalized_events,
            marker="o",
            linestyle="-",
            label=f"{max_prime}",
        )

    # configure graph
    plt.title(
        f"Performance of Sysbench CPU Benchmark with Time = {max_time}, Prime Number Limit = {prime_number}"
    )
    plt.legend(title="Number of Iterations")
    plt.xlabel("Number of Threads")
    plt.ylabel("Number of Events")
    plt.grid(True)

    # save graph as a png
    plt.savefig("data_plot_{}.png".format(datetime_stamp))


if __name__ == "__main__":

    data_frame = run_benchmark()
    create_csv_file(data_frame)
    create_graph_file(data_frame)
    determine_optimal_threads(data_frame)
